{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pallavichandan/PySpark_Tutorial/blob/basics/Pyspark_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "installing and importing PySpark"
      ],
      "metadata": {
        "id": "_lg0iSEhICs8"
      },
      "id": "_lg0iSEhICs8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8794e79-f996-4fc1-af3d-6c878054314a",
      "metadata": {
        "id": "f8794e79-f996-4fc1-af3d-6c878054314a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11fab85c-234d-4011-dc37-cf642bcfb3cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d3bc6939780>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/73/e5/c9eb78cc982dafb7b5834bc5c368fe596216c8b9f7c4b4ffa104c4d2ab8f/pyspark-3.5.1.tar.gz\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=d4e49b44748ba08785345a73a559e7312ca0b3c49a7f87cf851f006eb7e22c4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "# !pip install pyspark\n",
        "import pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de05dbeb-243b-471f-95fc-8d8e80a68824",
      "metadata": {
        "id": "de05dbeb-243b-471f-95fc-8d8e80a68824"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5831d87-4549-47e2-acb2-cff1fb361e6d",
      "metadata": {
        "id": "d5831d87-4549-47e2-acb2-cff1fb361e6d"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"practice\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating PySpark DataFrame"
      ],
      "metadata": {
        "id": "Rp4uJXkaKKNm"
      },
      "id": "Rp4uJXkaKKNm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ebbf70-fe15-477b-ac82-495bfe464109",
      "metadata": {
        "id": "29ebbf70-fe15-477b-ac82-495bfe464109"
      },
      "outputs": [],
      "source": [
        "data = [(1,\"John\",\"NY\"),(2,\"Alan\",\"DC\"),(3,\"Dabby\",\"NJ\"),(4,\"Joey\",\"NY\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4607da17-7cc8-4052-b55b-6edee87f602d",
      "metadata": {
        "id": "4607da17-7cc8-4052-b55b-6edee87f602d"
      },
      "outputs": [],
      "source": [
        "columns = [\"Id\",\"Name\",\"Location\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d240dd03-0a48-439f-b99c-bdeffd86cec0",
      "metadata": {
        "id": "d240dd03-0a48-439f-b99c-bdeffd86cec0"
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame( data,columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bab3094-1ed3-4e61-a317-dd195c872f18",
      "metadata": {
        "id": "6bab3094-1ed3-4e61-a317-dd195c872f18",
        "outputId": "ab08c51b-a07f-4a53-b634-8b053df157e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----+--------+\n",
            "| Id| Name|Location|\n",
            "+---+-----+--------+\n",
            "|  1| John|      NY|\n",
            "|  2| Alan|      DC|\n",
            "|  3|Dabby|      NJ|\n",
            "|  4| Joey|      NY|\n",
            "+---+-----+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh4hRBiTrqV2",
        "outputId": "be1289fe-ac0b-4f2f-8e7c-1953cb9e3e37"
      },
      "id": "vh4hRBiTrqV2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, Id: string, Name: string, Location: string]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ5PZZwUrtvb",
        "outputId": "3359b15a-8575-4fbe-a7d2-9d4d9f5d2175"
      },
      "id": "UZ5PZZwUrtvb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Id: long (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Location: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create PySpark DataFrame from multiple lists"
      ],
      "metadata": {
        "id": "OlRSoRIFKOIV"
      },
      "id": "OlRSoRIFKOIV"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}